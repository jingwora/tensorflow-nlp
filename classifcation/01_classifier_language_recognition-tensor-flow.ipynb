{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02_classifier_language_recognition-tensor-flow.ipynb","version":"0.3.2","provenance":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"1cjSf7flvS5C","colab_type":"text"},"source":["As usual we start loading the packages that we will use in our notebook"]},{"cell_type":"code","metadata":{"id":"jufy2xAyvS5D","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","import tensorflow_hub as hub\n","import numpy as np\n","import pandas as pd\n","from sklearn import model_selection\n","from sklearn.preprocessing import LabelEncoder \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RUBeBggTwoPf","colab_type":"code","outputId":"aeb68ac0-0ac5-4e83-a9f3-c8c9a09ff75a","executionInfo":{"status":"ok","timestamp":1563011800210,"user_tz":-540,"elapsed":48342,"user":{"displayName":"Jing Wora","photoUrl":"https://lh5.googleusercontent.com/-8KmqWgosdgw/AAAAAAAAAAI/AAAAAAAAAEI/E5ThPOWQm-M/s64/photo.jpg","userId":"14098338404840441752"}},"colab":{"base_uri":"https://localhost:8080/","height":128}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fd2HVB3Yw2w4","colab_type":"code","outputId":"048c5de2-1d5e-42aa-df25-cff5eaa147d6","executionInfo":{"status":"ok","timestamp":1563011854103,"user_tz":-540,"elapsed":2519,"user":{"displayName":"Jing Wora","photoUrl":"https://lh5.googleusercontent.com/-8KmqWgosdgw/AAAAAAAAAAI/AAAAAAAAAEI/E5ThPOWQm-M/s64/photo.jpg","userId":"14098338404840441752"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!ls \"/content/drive/My Drive/dataset/Advanced-NLP-TF/\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["_about.txt  ita.txt  reviews.csv  test.csv  train.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MIGZEz4WvS5G","colab_type":"code","outputId":"a32d0185-053c-4924-dd3f-2c9fd564fbb7","executionInfo":{"status":"ok","timestamp":1563011903990,"user_tz":-540,"elapsed":3101,"user":{"displayName":"Jing Wora","photoUrl":"https://lh5.googleusercontent.com/-8KmqWgosdgw/AAAAAAAAAAI/AAAAAAAAAEI/E5ThPOWQm-M/s64/photo.jpg","userId":"14098338404840441752"}},"colab":{"base_uri":"https://localhost:8080/","height":440}},"source":["dataset = \"/content/drive/My Drive/dataset/Advanced-NLP-TF/train.csv\"\n","train_df = pd.read_csv(dataset)#here we have the dataset we extracted\n","train_df.head()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>title</th>\n","      <th>author</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n","      <td>Darrell Lucus</td>\n","      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n","      <td>Daniel J. Flynn</td>\n","      <td>Ever get the feeling your life circles the rou...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Why the Truth Might Get You Fired</td>\n","      <td>Consortiumnews.com</td>\n","      <td>Why the Truth Might Get You Fired October 29, ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n","      <td>Jessica Purkiss</td>\n","      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Iranian woman jailed for fictional unpublished...</td>\n","      <td>Howard Portnoy</td>\n","      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id  ... label\n","0   0  ...     1\n","1   1  ...     0\n","2   2  ...     1\n","3   3  ...     1\n","4   4  ...     1\n","\n","[5 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"pOO2D0levS5L","colab_type":"code","outputId":"b495ad71-210d-4345-921c-6de8b8d90708","executionInfo":{"status":"ok","timestamp":1563012031235,"user_tz":-540,"elapsed":645,"user":{"displayName":"Jing Wora","photoUrl":"https://lh5.googleusercontent.com/-8KmqWgosdgw/AAAAAAAAAAI/AAAAAAAAAEI/E5ThPOWQm-M/s64/photo.jpg","userId":"14098338404840441752"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(train_df.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(20800, 5)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GbZsK1tAvS5O","colab_type":"text"},"source":["A key step is to label encode the target variable from text to number\n"]},{"cell_type":"code","metadata":{"id":"36Aa7DfNvS5P","colab_type":"code","outputId":"e67ba566-9f42-45cf-9416-f5b74112212b","executionInfo":{"status":"error","timestamp":1563012078654,"user_tz":-540,"elapsed":764,"user":{"displayName":"Jing Wora","photoUrl":"https://lh5.googleusercontent.com/-8KmqWgosdgw/AAAAAAAAAAI/AAAAAAAAAEI/E5ThPOWQm-M/s64/photo.jpg","userId":"14098338404840441752"}},"colab":{"base_uri":"https://localhost:8080/","height":764}},"source":["Y = train_df['language']\n","encoder = LabelEncoder()\n","encoder.fit(Y)\n","Y = encoder.transform(Y)\n","Y = tf.keras.utils.to_categorical(\n","    Y,\n","    num_classes=4 #equals to the number of languages\n","    \n",")"],"execution_count":0,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'language'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-cc5c814c4aa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'language'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m Y = tf.keras.utils.to_categorical(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'language'"]}]},{"cell_type":"markdown","metadata":{"id":"GZAGaRjIvS5R","colab_type":"text"},"source":["As we mentioned in the slides we will perform the previous text processing steps except for stopword removal."]},{"cell_type":"code","metadata":{"id":"Ai6bLyPHvS5S","colab_type":"code","colab":{}},"source":["train_df['sentence_lower'] = train_df[\"sentence\"].str.lower()\n","train_df['sentence_no_punctuation'] = train_df['sentence_lower'].str.replace('[^\\w\\s]','')\n","train_df['sentence_no_punctuation'] = train_df[\"sentence_no_punctuation\"].fillna(\"fillna\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"K32uMGPJvS5U","colab_type":"code","colab":{}},"source":["max_features=5000 #we set maximum number of words to 5000\n","maxlen=400 #we set maximum sequence length to 400"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gis3dRtDvS5X","colab_type":"code","colab":{}},"source":["tok = tf.keras.preprocessing.text.Tokenizer(num_words=max_features) #again tokenizer step"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x0ArB_y5vS5a","colab_type":"code","colab":{}},"source":["tok.fit_on_texts(list(train_df['sentence_no_punctuation'])) #fit to cleaned text"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fmMatCx6vS5c","colab_type":"code","outputId":"fa866e3b-8775-4113-87bb-02e839452ff0","colab":{}},"source":["print(len(tok.word_index))\n","vocab_size = len(tok.word_index) + 1 \n","#this represents the number of words that we tokenize different from max_features but necessary for\n","#the definition of the dimension of the embedding space"],"execution_count":0,"outputs":[{"output_type":"stream","text":["51630\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SJkws6gNvS5f","colab_type":"code","colab":{}},"source":["train_df = tok.texts_to_sequences(list(train_df['sentence_no_punctuation'])) #this is how we create sequences\n","train_df = tf.keras.preprocessing.sequence.pad_sequences(train_df, maxlen=maxlen) #let's execute pad step"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pbxgrzSOvS5i","colab_type":"code","colab":{}},"source":["\n","from sklearn.model_selection import train_test_split #divide into train and test set"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EStrqFpGvS5k","colab_type":"code","colab":{}},"source":["X_train, X_test, y_train, y_test = train_test_split(train_df, Y, test_size=0.1, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZPfFkFXkvS5m","colab_type":"code","colab":{}},"source":["embedding_dim = 50 #this is the final dimension of the embedding space.\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kc1ppF9gvS5p","colab_type":"text"},"source":["Let's write down the model"]},{"cell_type":"code","metadata":{"id":"SUcMpS7FvS5p","colab_type":"code","colab":{}},"source":["model = tf.keras.models.Sequential([\n","  tf.keras.layers.Embedding(input_dim=vocab_size, #embedding input\n","                           output_dim=embedding_dim,#embedding output\n","                           input_length=maxlen), #maximum length of an input sequence\n","  tf.keras.layers.Flatten(), #flatten layer\n","\n","  tf.keras.layers.Dense(4, activation=tf.nn.softmax) #ouput layer a Dense layer with 4 probabilities\n","  #we also define our final activation function which is the softmax function typical for multiclass\n","  #classifiction problems\n","\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RSGhhRfUvS5r","colab_type":"code","colab":{}},"source":["model.compile(optimizer='adam',\n","              loss='categorical_crossentropy', #we recommend this loss function you\n","              metrics=['accuracy'])\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dQJI7vrxvS5v","colab_type":"code","outputId":"a4ff7ee3-31eb-4845-8c66-f672a04aac5c","colab":{}},"source":["model.summary() #here we show the architecture "],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, 400, 50)           2581550   \n","_________________________________________________________________\n","flatten_2 (Flatten)          (None, 20000)             0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 4)                 80004     \n","=================================================================\n","Total params: 2,661,554\n","Trainable params: 2,661,554\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Nszmv8d8vS5z","colab_type":"code","outputId":"09738c38-c495-4576-bd80-be991e28f0e7","colab":{}},"source":["model.fit(np.array(X_train), np.array(y_train), epochs=3) #let's fit the model"],"execution_count":0,"outputs":[{"output_type":"stream","text":["C:\\Users\\Admin\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/3\n","3269/3269 [==============================] - 3s 1ms/step - loss: 0.8189 - acc: 0.7473\n","Epoch 2/3\n","3269/3269 [==============================] - 3s 950us/step - loss: 0.0801 - acc: 0.9966\n","Epoch 3/3\n","3269/3269 [==============================] - 3s 942us/step - loss: 0.0268 - acc: 0.9976\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x215a88ed2b0>"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"markdown","metadata":{"id":"FElAw1DUvS53","colab_type":"text"},"source":["Remember the train_test_split? now we use the test to evaluate our model"]},{"cell_type":"code","metadata":{"id":"5sWuvyzHvS54","colab_type":"code","outputId":"3d718cbf-038c-45a0-af4a-85488cb5442e","colab":{}},"source":["model.evaluate(np.array(X_test), np.array(y_test)) "],"execution_count":0,"outputs":[{"output_type":"stream","text":["364/364 [==============================] - 0s 221us/step\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[0.013595647582845701, 1.0]"]},"metadata":{"tags":[]},"execution_count":84}]},{"cell_type":"markdown","metadata":{"id":"B57GedGivS57","colab_type":"text"},"source":["LOOKS LIKE WE HAVE A PERFECT MODEL!! \n","LET'S TAKE A LOOK AT THE CONFUSION MATRIX OF OUR EVALUATION SET!!"]},{"cell_type":"code","metadata":{"id":"Lb523zuYvS58","colab_type":"code","colab":{}},"source":["from sklearn.metrics import confusion_matrix #we import this package from sklearn and output it\n","predictions = model.predict(X_test) #here we make predictions\n","cm = confusion_matrix(predictions.argmax(axis=1), y_test.argmax(axis=1))#we generate the confusion matrix"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OPSJ4cPMvS5-","colab_type":"code","outputId":"5c020092-f04b-43c3-f87a-86cf1829094b","colab":{}},"source":["cm #well this is really perfect!"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 91,   0,   0,   0],\n","       [  0,  88,   0,   0],\n","       [  0,   0, 102,   0],\n","       [  0,   0,   0,  83]], dtype=int64)"]},"metadata":{"tags":[]},"execution_count":86}]},{"cell_type":"markdown","metadata":{"id":"L0S-Ucp7vS6C","colab_type":"text"},"source":["Let's try brand new text"]},{"cell_type":"code","metadata":{"id":"jn0htv6OvS6D","colab_type":"code","outputId":"30d2f90e-9341-48f7-c55d-788bce6797f2","colab":{}},"source":["#these are the codes for each language in order to evaluate properly\n","print('english', encoder.transform(['english']))\n","print('french', encoder.transform(['french']))\n","print('italian', encoder.transform(['italian']))\n","print('spanish', encoder.transform(['spanish']))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["english [0]\n","french [1]\n","italian [2]\n","spanish [3]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bfp8yEpOvS6G","colab_type":"text"},"source":["In this experiment we will predict the language of the same sentence in the different languages"]},{"cell_type":"code","metadata":{"id":"pML-fdd9vS6H","colab_type":"code","colab":{}},"source":["#new_text = [\"tensorflow is a great tool you can find a lot of tutorials from packt\"]\n","#new_text = [\"tensorflow est un excellent outil vous pouvez trouver beaucoup de tutoriels de packt\"]\n","#new_text = [\"tensorflow è un ottimo strumento puoi trovare molti tutorial di packt\"]\n","new_text = [\"tensorflow es una gran herramienta puedes encontrar muchos tutoriales de packt\"]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D4Mpw6u9vS6J","colab_type":"code","colab":{}},"source":["test_text = tok.texts_to_sequences(new_text) #this is how we create sequences\n","test_text = tf.keras.preprocessing.sequence.pad_sequences(test_text, maxlen=maxlen) #let's execute pad step"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UUg7UZQRvS6L","colab_type":"code","outputId":"99c99132-b65d-4e4d-8568-4db73602e947","colab":{}},"source":["np.set_printoptions(suppress=True)\n","predictions = model.predict(test_text)\n","print(predictions.argmax())\n","print(predictions) #spanish you can get confused with italian which makes sense since they are more similar languages"],"execution_count":0,"outputs":[{"output_type":"stream","text":["3\n","[[0.05204275 0.0830349  0.10003749 0.7648848 ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"j1gz6erQvS6N","colab_type":"code","colab":{}},"source":["import wikipedia"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VG5gXWkxvS6P","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mYyfJsErvS6Q","colab_type":"text"},"source":["Let's build a brand new data set with only spanish and let's see if we recognize it ..."]},{"cell_type":"code","metadata":{"id":"iW34jel2vS6R","colab_type":"code","outputId":"2006eb7a-3b3a-4bb6-fa65-974e0439585c","colab":{}},"source":["new_wiki_text = []\n","wikipedia.set_lang('es')\n","for i in range(0, 5):\n","    print(i)\n","    random = wikipedia.random(1)\n","       \n","    try:\n","        new_wiki_text.append([wikipedia.page(random).summary])\n","    except wikipedia.exceptions.DisambiguationError as e:\n","        random = wikipedia.random(1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["0\n","1\n","2\n","3\n","4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hc_HV8RhvS6V","colab_type":"code","outputId":"a2cf295a-8e65-4867-de8d-aa2eac6c57d5","colab":{}},"source":["new_wiki_text = pd.DataFrame(new_wiki_text)\n","new_wiki_text.columns = ['sentence']\n","new_wiki_text"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Pontefract es un pueblo del distrito de Wakefi...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Joan de Giorgio Vitelli i Simon (Alguer 1870 -...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Glitter es una banda sonora original y el octa...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Bajo el apelativo de Cocinas del Sureste Asiát...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Neolucanus diffusus es una especie de coleópte...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence\n","0  Pontefract es un pueblo del distrito de Wakefi...\n","1  Joan de Giorgio Vitelli i Simon (Alguer 1870 -...\n","2  Glitter es una banda sonora original y el octa...\n","3  Bajo el apelativo de Cocinas del Sureste Asiát...\n","4  Neolucanus diffusus es una especie de coleópte..."]},"metadata":{"tags":[]},"execution_count":102}]},{"cell_type":"code","metadata":{"id":"c4v62w1GvS6X","colab_type":"code","colab":{}},"source":["new_wiki_text['sentence_lower'] = new_wiki_text[\"sentence\"].str.lower()\n","new_wiki_text['sentence_no_punctuation'] = new_wiki_text['sentence_lower'].str.replace('[^\\w\\s]','')\n","new_wiki_text['sentence_no_punctuation'] = new_wiki_text[\"sentence_no_punctuation\"].fillna(\"fillna\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UQbHMp_FvS6Z","colab_type":"code","colab":{}},"source":["np.set_printoptions(suppress=True)\n","test_wiki_text = tok.texts_to_sequences(list(new_wiki_text['sentence_no_punctuation'] )) #this is how we create sequences\n","test_wiki_text = tf.keras.preprocessing.sequence.pad_sequences(test_wiki_text, maxlen=maxlen) #let's execute pad step"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ul7rz0W_vS6c","colab_type":"code","outputId":"89292a61-b2b4-403f-f78e-8dc7744e0ffa","colab":{}},"source":["predictions = model.predict(test_wiki_text)\n","print(predictions)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0.00000093 0.00010869 0.00000099 0.9998894 ]\n"," [0.00038548 0.00102032 0.00080112 0.9977931 ]\n"," [0.0000383  0.00060026 0.00007764 0.99928385]\n"," [0.00000019 0.00000787 0.00000026 0.99999166]\n"," [0.00212952 0.01033464 0.00334356 0.98419225]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ki57SxlDvS6f","colab_type":"code","outputId":"6701fc60-45f1-4fe3-f6b2-8905e434f8bd","colab":{}},"source":["print('english', encoder.transform(['english']))\n","print('french', encoder.transform(['french']))\n","print('italian', encoder.transform(['italian']))\n","print('spanish', encoder.transform(['spanish']))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["english [0]\n","french [1]\n","italian [2]\n","spanish [3]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"615GZidJvS6h","colab_type":"text"},"source":["WE DID A GOOD JOB!!"]},{"cell_type":"code","metadata":{"id":"E6UMmGzLvS6i","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}